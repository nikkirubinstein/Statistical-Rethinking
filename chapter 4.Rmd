---
title: "Statistical Rethinking - Chapter 4"
author: "Nikki Rubinstein"
output:
  html_document: 
    toc: yes
  html_notebook: 
    theme: united
    toc: yes
---

# Linear Models

Linear regression attempts to learn about the mean and variance of a measurement using a Gaussian distribution to describe uncertainty.

## 4.1 Why normal distributions are normal

### 4.1.1 Normal by addition

Simulating 1000 experiments of 16 coin flips, with a step of randomly chosen size between 0 and 1 taken to the left for heads and right for tails. The resultant distribution is normal

```{r}
pos <- replicate(1000, sum(runif(16, -1, 1)))
hist(pos)
plot(density(pos))
```

Any process that adds together random values from the same distribution converges to normal - the central limit theorem.

### 4.1.2 Normal by multiplication

Simulating 10,000 experiments in which the effects of 12 alleles multiply to generate a growth factor. Convergence to a normal distribution occurs because the effect of multiplying small numbers approximates addition.

```{r}
growth <- replicate(10000, prod(1 + runif(12, 0, 0.1)))
plot(density(growth))
```
 

```{r}
big <- replicate (10000, prod(1 + runif(12, 0, 0.5)))
small <- replicate(10000, prod(1 + runif(12, 0, 0.01)))
plot(density(big), main = "Big values")
plot(density(small), main = "Small values")
```

### 4.1.3 Normal by log-multiplication

Although multiplying large deviates doesn't produce a Gaussian distribution on a linear scale, it does produce a Gaussian distribution when converted to a log scale. This is because adding logs is the equivalent of multiplying the original numbers.

```{r}
log.big <- replicate(10000, log(prod(1 + runif(12, 0, 0.5))))
plot(density(log.big), main = "Big values on a log scale")
```


### 4.1.4 Using Gaussian distributions

The Gaussian is a member of a family of fundamental natural distributions known as the exponential family (ontological justification). The Gaussian distribution is the shape that can be realised in the largest number of ways and does not introduce any new assumptions (epistemological justification). The Gaussian distribution is essentially the exponent of a negative quadratic.

## 4.2 A language for describing models

Requirements for a model:
1. Outcome variables
2. Gaussian likelihood distribution (the plausability of individual observations of the outcome variables)
3. Predictor variables
4. Define model parameters (the relationship between the likelihood function and the predictor variables)
5. Priors for all model paramters

### 4.2.1 Re-describing the globe tossing model

The posterior probability of p is proportional to the product of the likelihood (binomial distribution with 6 out of a possible 9) and the prior (uniform distribution between 0 and 1).

```{r}
w <- 6
n <- 9
p_grid <- seq(from = 0, to = 1, length.out = 100)
posterior <- dbinom(w, n, p_grid) * dunif(p_grid, 0, 1)
posterior <- posterior / sum(posterior)
plot(posterior)
```

## 4.3 A Gaussian model of height

### 4.3.1 The data

Partial census data for the Dobe area !Kung San in the 1960s: height - cms; weight - kgs; age - years; and maleness - 1 male, 0 female.
```{r}
library(rethinking)
library(dplyr)
data(Howell1)
d <- Howell1
# filter out people under 18 years of age
d2 <- d %>% filter(age >= 18)
```

### 4.3.1 The model

Adult heights are nearly always approximately normal.

```{r}
# The distribution of heights
hist(d2$height)
```

h<sub>i</sub> ~ Normal($\mu , \sigma$)

This model is often described as being independent and identically distributed (IID). This is an epistemological assumption, inherent to the model, not necessarily the external world.

We also need priors for the $\mu$ and $\sigma$ parameters of the above likelihood functoin.

$\mu$ ~ Normal(178, 20)

$\sigma$ ~ Uniform(0, 50)

```{r}
plot(100:250, dnorm(100:250, 178, 20), main = "Prior for mu", type = "l")

plot(-10:60, dunif(-10:60, 0, 50), type = "l", main = "Prior for sigma")
```

Heights can be simulated by sampling from the prior distribution.

```{r}
sample_mu <- rnorm(10000, 178, 20)
sample_sigma <- runif(10000, 0, 50)
prior_h <- rnorm(10000, sample_mu, sample_sigma)
hist(prior_h)
```

